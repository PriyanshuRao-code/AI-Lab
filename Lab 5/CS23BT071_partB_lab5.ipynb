{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d0eb9c7-7979-4bbf-aeec-4220306cd277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "da668b22-9be0-40e8-af2c-99bab945fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('WDBC_Train.csv')\n",
    "valid = pd.read_csv('WDBC_Validation.csv')\n",
    "test = pd.read_csv('WDBC_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "877a8f4b-b66b-4e85-bf75-b977a76689a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train.iloc[:, 1:], train.iloc[:, 0]\n",
    "X_valid, y_valid = valid.iloc[:, 1:], valid.iloc[:, 0]\n",
    "X_test, y_test = test.iloc[:, 1:], test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "69f317fb-8199-4a96-929d-6a1be347b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "X={}\n",
    "X[0] = X_train[y_train == 0]\n",
    "X[1] = X_train[y_train == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d6e182e-82bd-432b-8c3a-ddab16fff77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_mean[0] = np.mean(X_0,axis=0)\n",
    "# X_mean[1] = np.mean(X_1, axis=0)\n",
    "\n",
    "# X_cov[0] = np.cov(X_0.T)\n",
    "# X_cov[1] = np.cov(X_1.T)\n",
    "\n",
    "# X_prior_0 = X_0.shape[0]/X_train.shape[0]\n",
    "# X_prior_1 = X_1.shape[0]/X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "01a2cb26-7bf8-4b13-aee2-8ef11e9c13c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0,1]\n",
    "X_mean = {}\n",
    "X_cov={}\n",
    "X_prior={}\n",
    "for c in classes:\n",
    "    X_mean[c] = np.mean(X[c],axis=0)\n",
    "    X_cov[c] = np.cov(X[c].T)\n",
    "    X_prior[c] = X[c].shape[0]/X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "426773e2-ba77-4fb2-8b04-7d8a81f3f60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y test predications:\n",
      "[0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0\n",
      " 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 1\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 0\n",
      " 0 0 0]\n",
      "\n",
      "\n",
      "y valid predications:\n",
      "[0 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 1 1 0\n",
      " 1 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1\n",
      " 1 0 1]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def posterior_func(X):\n",
    "    likelihood = {}\n",
    "    post = []\n",
    "    posterior =[]\n",
    "    for c in classes:\n",
    "        likelihood = multivariate_normal(mean=X_mean[c], cov=X_cov[c], allow_singular=True).pdf(X)\n",
    "        # print(f\"Likelihood for class {c}:\\n {likelihood}\")\n",
    "        post.append(likelihood * X_prior[c])\n",
    "    post = np.array(post)\n",
    "    # print (post)\n",
    "    posterior = post/np.sum(post, axis=0)\n",
    "    # print(posterior)\n",
    "    return np.argmax(posterior, axis=0)\n",
    "\n",
    "y_test_pred= posterior_func(X_test)\n",
    "print(f\"y test predications:\\n{y_test_pred}\\n\\n\")\n",
    "\n",
    "y_valid_pred = posterior_func(X_valid)\n",
    "print(f\"y valid predications:\\n{y_valid_pred}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2a938e9-f5c8-4205-862c-3875734d4944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Validation data:\n",
      "\n",
      "Confusion matrix: \n",
      "[[65  6]\n",
      " [ 4 39]]\n",
      "Accuracy: \t0.9122807017543859\n",
      "Precision: \t0.8666666666666667\n",
      "Recall: \t0.9069767441860465\n",
      "F1-score: \t0.8863636363636364\n",
      "\n",
      "\n",
      "Performance for Test data:\n",
      "\n",
      "Confusion matrix: \n",
      "[[64  8]\n",
      " [ 3 39]]\n",
      "Accuracy: \t0.9035087719298246\n",
      "Precision: \t0.8297872340425532\n",
      "Recall: \t0.9285714285714286\n",
      "F1-score: \t0.8764044943820225\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def performance(model_name, y_true, y_pred):\n",
    "    print(f\"Performance for {model_name}:\\n\")\n",
    "    print(f\"Confusion matrix: \\n{confusion_matrix(y_true,y_pred)}\")\n",
    "    print(f\"Accuracy: \\t{accuracy_score(y_true, y_pred)}\")\n",
    "    print(f\"Precision: \\t{precision_score(y_true, y_pred)}\")\n",
    "    print(f\"Recall: \\t{recall_score(y_true, y_pred)}\")\n",
    "    print(f\"F1-score: \\t{f1_score(y_true, y_pred)}\\n\\n\")\n",
    "\n",
    "performance(\"Validation data\", y_valid, y_valid_pred)\n",
    "performance(\"Test data\", y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18a68da-e62b-4bd8-8513-bffba0688fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
